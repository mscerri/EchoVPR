{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\\src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from configs.utils import get_config\n",
    "from echovpr.datasets.utils import get_dataset, save_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config(\"configs\\\\train_mlp_nordland_full.ini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=\"echovpr_nordland_hl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(artifact_name: str, model_name: str) -> str:\n",
    "    model_artifact = run.use_artifact(artifact_name, type='model')\n",
    "    model_dir = model_artifact.download()\n",
    "    return os.path.join(model_dir, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = load_model('mscerri/echovpr_nordland_hl/model-qsp4802p:v0', 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init MLP and Lightning Modules\n",
    "in_features=int(config['model_in_features'])\n",
    "hidden_features=int(config['model_hidden_features'])\n",
    "out_features=int(config['model_out_features'])\n",
    "\n",
    "model = nn.Sequential(OrderedDict([\n",
    "          ('hl', nn.Linear(in_features=in_features, out_features=hidden_features, bias=True)),\n",
    "          ('out', nn.Linear(in_features=hidden_features, out_features=out_features, bias=True))\n",
    "        ]))\n",
    "\n",
    "pl_model = ClassificationTask.load_from_checkpoint(model_path, map_location={'cuda:0':'cuda:0'}, model=model, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_model.eval()\n",
    "pl_model.freeze()\n",
    "\n",
    "pl_model = pl_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(model, dataLoader):\n",
    "    x_processed_list = []\n",
    "    y_target_list = []\n",
    "    \n",
    "    for x, y_target in dataLoader:\n",
    "        x = x.cuda()\n",
    "        x_processed = model(x)\n",
    "\n",
    "        x_processed_list.append(x_processed.cpu())\n",
    "        y_target_list.append(y_target)\n",
    "\n",
    "    return (torch.vstack(x_processed_list), torch.vstack(y_target_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Datasets\n",
    "\n",
    "summer_dataset = get_dataset(config['dataset_nordland_summer_netvlad_repr_file_path'])\n",
    "print(f\"Summer dataset size: {len(summer_dataset)}\")\n",
    "summer_dataLoader = DataLoader(summer_dataset, num_workers=int(config['dataloader_threads']), batch_size=int(config['train_batchsize']), shuffle=False)\n",
    "\n",
    "winter_dataset = get_dataset(config['dataset_nordland_winter_netvlad_repr_file_path'])\n",
    "print(f\"Winter dataset size: {len(winter_dataset)}\")\n",
    "winter_dataLoader = DataLoader(winter_dataset, num_workers=int(config['dataloader_threads']), batch_size=int(config['train_batchsize']), shuffle=False)\n",
    "\n",
    "spring_dataset = get_dataset(config['dataset_nordland_spring_netvlad_repr_file_path'])\n",
    "print(f\"Spring dataset size: {len(spring_dataset)}\")\n",
    "spring_dataLoader = DataLoader(spring_dataset, num_workers=int(config['dataloader_threads']), batch_size=int(config['train_batchsize']), shuffle=False)\n",
    "\n",
    "fall_dataset = get_dataset(config['dataset_nordland_fall_netvlad_repr_file_path'])\n",
    "print(f\"Fall dataset size: {len(fall_dataset)}\")\n",
    "fall_dataLoader = DataLoader(fall_dataset, num_workers=int(config['dataloader_threads']), batch_size=int(config['train_batchsize']), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = model.get_submodule('hl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nordland_summer_repr = process(encoder, summer_dataLoader)\n",
    "save_tensor(nordland_summer_repr, config['dataset_nordland_summer_hidden_repr_file_path'])\n",
    "\n",
    "nordland_winter_repr = process(encoder, winter_dataLoader)\n",
    "save_tensor(nordland_winter_repr, config['dataset_nordland_winter_hidden_repr_file_path'])\n",
    "\n",
    "nordland_spring_repr = process(encoder, spring_dataLoader)\n",
    "save_tensor(nordland_spring_repr, config['dataset_nordland_spring_hidden_repr_file_path'])\n",
    "\n",
    "nordland_fall_repr = process(encoder, fall_dataLoader)\n",
    "save_tensor(nordland_fall_repr, config['dataset_nordland_fall_hidden_repr_file_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmscerri\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/mscerri/EchoVPR/runs/ht0eg28z\" target=\"_blank\">ruby-hill-23</a></strong> to <a href=\"https://wandb.ai/mscerri/EchoVPR\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-qsp4802p:v0, 181.65MB. 1 files... Done. 0:0:0\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "run = wandb.init()\n",
    "artifact = run.use_artifact('mscerri/echovpr_nordland_hl/model-qsp4802p:v0', type='model')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\artifacts\\\\model-qsp4802p-v0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "full_checkpoint = torch.load(os.path.join(artifact_dir, 'model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hl.weight',\n",
       "              tensor([[ 0.0580, -0.0595, -0.0201,  ...,  0.7784, -0.9948,  0.1011],\n",
       "                      [ 0.2330, -0.2344,  0.0531,  ..., -0.0458, -0.4421,  0.6790],\n",
       "                      [-0.2724, -0.1121,  0.0261,  ...,  0.4420, -0.4574, -0.3452],\n",
       "                      ...,\n",
       "                      [ 0.1165, -0.1799, -0.1070,  ..., -0.5386,  0.6004, -1.1713],\n",
       "                      [ 0.9386, -0.1423, -0.1661,  ..., -0.3170,  0.5763, -0.7798],\n",
       "                      [ 0.1785, -0.0029, -0.1679,  ...,  0.2226,  0.4547, -0.2574]],\n",
       "                     device='cuda:0')),\n",
       "             ('hl.bias',\n",
       "              tensor([-0.0684, -0.2212,  0.2363, -0.1097, -0.0574,  0.0649, -0.1003, -0.0957,\n",
       "                      -0.2649, -0.1646,  0.1428,  0.2115, -0.0575, -0.3424, -0.1166, -0.0081,\n",
       "                      -0.0983,  0.0179, -0.0492, -0.0648, -0.0081,  0.0387,  0.1512, -0.2176,\n",
       "                      -0.1978, -0.1704, -0.1919, -0.1081, -0.0407,  0.1552,  0.1343,  0.1102,\n",
       "                       0.3577,  0.4289,  0.2703,  0.0286, -0.2106, -0.2581,  0.1734,  0.0727,\n",
       "                       0.0969,  0.0402,  0.1493, -0.0261,  0.0636,  0.0261,  0.0194, -0.0340,\n",
       "                      -0.1202,  0.0706, -0.1782,  0.0009, -0.0578, -0.0237,  0.1812,  0.2889,\n",
       "                      -0.0383, -0.1038, -0.1884,  0.1328,  0.1109, -0.1218,  0.0289,  0.1914,\n",
       "                       0.0726,  0.0505,  0.0327, -0.0763, -0.0378, -0.1084,  0.0505, -0.1410,\n",
       "                      -0.1693,  0.0797, -0.1948, -0.1133,  0.1933, -0.1177,  0.2394,  0.0971,\n",
       "                       0.1291,  0.0885,  0.0495, -0.3444, -0.0062, -0.1533, -0.0408,  0.0608,\n",
       "                      -0.1229, -0.1640, -0.1279,  0.0948, -0.0964,  0.0187, -0.1213,  0.2189,\n",
       "                       0.1649,  0.0930,  0.0221, -0.4208, -0.1821, -0.0554, -0.2256,  0.2211,\n",
       "                       0.0260,  0.1123, -0.0582,  0.0867, -0.2899,  0.1972,  0.0640, -0.2589,\n",
       "                       0.1332, -0.1459, -0.0898,  0.0193, -0.0501, -0.0586, -0.0630,  0.2729,\n",
       "                      -0.1372, -0.1114,  0.1044, -0.1413,  0.0631, -0.0243, -0.2050,  0.0184,\n",
       "                      -0.1406, -0.1328, -0.0764,  0.1260, -0.1098, -0.0948, -0.2664,  0.2724,\n",
       "                       0.0401,  0.1117,  0.0298, -0.0230, -0.1100,  0.1010,  0.1773, -0.1841,\n",
       "                      -0.0941,  0.1346,  0.0107, -0.0965,  0.3149,  0.1700, -0.1130, -0.0267,\n",
       "                      -0.2090,  0.0651, -0.0942, -0.0391, -0.0244, -0.1742, -0.0548,  0.3134,\n",
       "                      -0.0850, -0.1421,  0.0038,  0.1825, -0.1800,  0.1129, -0.1693, -0.0537,\n",
       "                      -0.1590, -0.0888,  0.0988,  0.1859,  0.1084, -0.1012,  0.0825, -0.0037,\n",
       "                      -0.0932, -0.0984,  0.0646, -0.1422, -0.0452,  0.2354,  0.0316,  0.0165,\n",
       "                      -0.1076, -0.1284, -0.0736, -0.1928,  0.1973, -0.1553, -0.0649, -0.1384,\n",
       "                      -0.1057,  0.0465, -0.0752, -0.1054,  0.2216,  0.0075, -0.2286, -0.3053,\n",
       "                      -0.0165,  0.3119, -0.0110, -0.3546, -0.0417,  0.0064, -0.1636,  0.2651,\n",
       "                      -0.2680, -0.1478, -0.0818,  0.2035,  0.0086,  0.1902, -0.1888,  0.3032,\n",
       "                      -0.0117,  0.0204, -0.2366, -0.1484, -0.0349, -0.3121, -0.1789, -0.0479,\n",
       "                       0.1132,  0.0079, -0.1128, -0.2322,  0.0505, -0.3060,  0.1721,  0.0620,\n",
       "                      -0.0746, -0.0604, -0.1178,  0.3916, -0.1688, -0.1851,  0.2347,  0.0393,\n",
       "                       0.2668,  0.1247, -0.0830,  0.1852,  0.2462,  0.1580, -0.1980,  0.1266,\n",
       "                      -0.1678,  0.0752,  0.0217,  0.3855, -0.2549, -0.0453,  0.1061, -0.2624,\n",
       "                       0.1957,  0.0734, -0.1232,  0.1285, -0.0872, -0.0784,  0.0729,  0.1163,\n",
       "                       0.0258,  0.0639,  0.0497,  0.1115, -0.0711,  0.0914,  0.1231,  0.1327,\n",
       "                       0.0854,  0.1265,  0.1889,  0.2104, -0.1321,  0.1924, -0.1341, -0.2775,\n",
       "                       0.1411, -0.1229,  0.1599, -0.0317, -0.0475, -0.0646, -0.1691,  0.2019,\n",
       "                       0.1707, -0.1517, -0.0624,  0.2131,  0.0309,  0.1310, -0.0027, -0.0676,\n",
       "                      -0.2266,  0.0610, -0.2088, -0.0062,  0.1106, -0.0020, -0.1959, -0.0265,\n",
       "                       0.1441, -0.0833, -0.1956,  0.1818,  0.1587, -0.0042,  0.1743, -0.1412,\n",
       "                       0.1363,  0.1714,  0.1394,  0.0556, -0.1822, -0.3655,  0.2716, -0.1216,\n",
       "                       0.1697, -0.1466,  0.0480, -0.0186,  0.0683,  0.1179, -0.2141,  0.2194,\n",
       "                       0.0800,  0.0749, -0.0023, -0.0824, -0.1224,  0.1927,  0.1907, -0.1997,\n",
       "                      -0.0892, -0.0709, -0.1342, -0.0443,  0.0986,  0.2641, -0.0795, -0.0011,\n",
       "                      -0.0084,  0.0521,  0.2378,  0.1370,  0.0956,  0.0279, -0.1518,  0.0919,\n",
       "                       0.1419, -0.0360, -0.0200,  0.0761,  0.1855, -0.0707, -0.0186, -0.0467,\n",
       "                       0.2460,  0.2825,  0.1626, -0.3476, -0.0048, -0.1624, -0.1493,  0.1095,\n",
       "                       0.1187,  0.0208,  0.0458, -0.1291,  0.4140, -0.1707, -0.2220,  0.0320,\n",
       "                       0.0867,  0.2373, -0.2397, -0.0831,  0.1674,  0.2290, -0.0919,  0.0474,\n",
       "                       0.1311, -0.1060,  0.1068,  0.0252, -0.0144,  0.0529,  0.0264,  0.1211,\n",
       "                      -0.1312,  0.0280, -0.2271, -0.0516, -0.2337, -0.0207, -0.0274,  0.0529,\n",
       "                       0.1176,  0.1112, -0.0350, -0.1104, -0.1095, -0.0491,  0.1269, -0.0364,\n",
       "                       0.1713, -0.1959,  0.1578, -0.0303, -0.0364, -0.1244, -0.3111, -0.0265,\n",
       "                       0.0060, -0.2478, -0.1063, -0.1978, -0.2213, -0.0205,  0.0223, -0.0637,\n",
       "                       0.1590,  0.1375,  0.1506,  0.0036,  0.0873,  0.2194,  0.0088,  0.1593,\n",
       "                       0.0809, -0.0262,  0.1571,  0.0187,  0.0690,  0.1566, -0.0316, -0.2163,\n",
       "                      -0.0103, -0.0876, -0.0356, -0.0304, -0.1646,  0.1055,  0.0362, -0.0559,\n",
       "                       0.0446, -0.0614,  0.1610,  0.2097, -0.1141, -0.0038,  0.2374,  0.0623,\n",
       "                       0.0966,  0.0930,  0.0664,  0.1134, -0.2299, -0.0507,  0.2476, -0.1238,\n",
       "                       0.1716, -0.0216, -0.0934,  0.0712,  0.0637,  0.3010, -0.0655, -0.0828,\n",
       "                      -0.0207, -0.1708, -0.0582, -0.1881,  0.0117, -0.2108,  0.0073, -0.0046,\n",
       "                      -0.2058,  0.0811,  0.1837,  0.1397,  0.0540,  0.1603, -0.0477, -0.1395,\n",
       "                       0.1134, -0.2105, -0.1512, -0.0662,  0.2235,  0.0722, -0.1375,  0.3052,\n",
       "                      -0.1911, -0.2014, -0.3289, -0.0418], device='cuda:0')),\n",
       "             ('out.weight',\n",
       "              tensor([[-0.6022,  0.2407, -0.3488,  ...,  0.2465,  0.2168, -0.4819],\n",
       "                      [-0.5068,  0.2353, -0.1820,  ...,  0.1872,  0.3064, -0.4054],\n",
       "                      [-0.3338,  0.1792, -0.4191,  ...,  0.3275,  0.2786, -0.3822],\n",
       "                      ...,\n",
       "                      [-0.3136,  0.1756, -0.3742,  ...,  0.3388,  0.2527, -0.4023],\n",
       "                      [-0.3620,  0.1698, -0.2700,  ...,  0.3884,  0.1879, -0.3664],\n",
       "                      [-0.3665,  0.1903, -0.1807,  ...,  0.4108,  0.2901, -0.3880]],\n",
       "                     device='cuda:0')),\n",
       "             ('out.bias',\n",
       "              tensor([-1.2507, -1.0861, -1.1991,  ..., -1.1981, -1.1576, -1.1606],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "new_full_checkpoint = OrderedDict()\n",
    "\n",
    "for name in full_checkpoint['state_dict']:\n",
    "    new_name = name.replace('model.', '')\n",
    "    new_full_checkpoint[new_name] = full_checkpoint['state_dict'][name]\n",
    "\n",
    "new_full_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(new_full_checkpoint, 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmscerri\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/mscerri/EchoVPR/runs/icte2078\" target=\"_blank\">hardy-surf-24</a></strong> to <a href=\"https://wandb.ai/mscerri/EchoVPR\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "run = wandb.init()\n",
    "artifact = run.use_artifact('uos_ml/echovpr_oxford_hl/hl_model_0qeoilym:v0', type='model')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hl.weight',\n",
       "              tensor([[-0.0867,  0.1801, -0.1248,  ...,  0.2166,  0.0102, -0.1475],\n",
       "                      [ 0.0046, -0.1201,  0.0351,  ..., -0.0901,  0.0950,  0.0374],\n",
       "                      [ 0.0496,  0.1536, -0.0529,  ...,  0.0763, -0.0642,  0.1419],\n",
       "                      ...,\n",
       "                      [ 0.0467,  0.0425, -0.0710,  ..., -0.0489, -0.0724,  0.0708],\n",
       "                      [-0.0456, -0.0895,  0.0199,  ...,  0.0808, -0.1201,  0.0946],\n",
       "                      [-0.0756,  0.0005,  0.0510,  ...,  0.1748, -0.0339, -0.1013]],\n",
       "                     device='cuda:0')),\n",
       "             ('hl.bias',\n",
       "              tensor([-0.1876,  0.1244, -0.1784, -0.1112, -0.1326, -0.1041, -0.1428, -0.1007,\n",
       "                      -0.2076,  0.1204,  0.1361,  0.1559,  0.1376, -0.1590, -0.1180,  0.1714,\n",
       "                      -0.0867,  0.1525,  0.1191,  0.1445,  0.1076,  0.0999,  0.1625,  0.1069,\n",
       "                      -0.1378, -0.1518,  0.1398,  0.1151,  0.1467, -0.1524, -0.1129,  0.1739,\n",
       "                       0.1000,  0.1721,  0.1780,  0.1133,  0.1540, -0.1537,  0.1619, -0.1142,\n",
       "                       0.1137, -0.0987,  0.1970, -0.1463, -0.1255, -0.1301,  0.1368, -0.2035,\n",
       "                       0.1171,  0.1513,  0.1323,  0.1964,  0.1347, -0.1904, -0.1313,  0.1369,\n",
       "                      -0.2237,  0.1553, -0.1310,  0.1122,  0.1543, -0.1967,  0.1425,  0.1437,\n",
       "                      -0.1379, -0.1138, -0.1487,  0.1372,  0.1230,  0.1219, -0.1612,  0.1294,\n",
       "                      -0.1360,  0.1168,  0.1267,  0.1321,  0.1166, -0.1237, -0.1309,  0.2042,\n",
       "                      -0.1621,  0.1341,  0.1886,  0.1745,  0.0870, -0.1871,  0.1290, -0.1701,\n",
       "                       0.1260,  0.0977, -0.1303,  0.1333,  0.0976, -0.0869,  0.0956, -0.1214,\n",
       "                       0.1367, -0.1224, -0.1407, -0.1834, -0.1323, -0.1364, -0.1340, -0.1405,\n",
       "                      -0.0924, -0.1524,  0.1248,  0.0824, -0.1417,  0.1033,  0.1531, -0.1196,\n",
       "                      -0.1437,  0.1297, -0.1332,  0.0965, -0.1394, -0.1443,  0.0897,  0.1302,\n",
       "                       0.1425, -0.1478,  0.1015,  0.1165, -0.1248,  0.1484,  0.1792, -0.1568,\n",
       "                      -0.1607,  0.0824, -0.1448,  0.1191, -0.1668, -0.1292,  0.1515,  0.1511,\n",
       "                      -0.1293, -0.1343,  0.1926, -0.0996, -0.1555,  0.1147, -0.0951, -0.1678,\n",
       "                       0.1267,  0.1120,  0.1602, -0.0920, -0.1055, -0.1778,  0.1328, -0.0728,\n",
       "                       0.1393, -0.1569,  0.1677,  0.1204, -0.0895, -0.1474, -0.1191,  0.1476,\n",
       "                      -0.1469, -0.1732,  0.1221, -0.1768, -0.1591, -0.1305, -0.1392,  0.1440,\n",
       "                      -0.1137,  0.1948, -0.1773,  0.1482,  0.1374, -0.1481, -0.1092,  0.2352,\n",
       "                       0.1311,  0.1591, -0.1186, -0.1100,  0.1048,  0.1382, -0.1216,  0.1150,\n",
       "                      -0.1041,  0.1144,  0.1370, -0.1787, -0.1308, -0.1324, -0.1619, -0.1561,\n",
       "                      -0.1429, -0.1249, -0.1200,  0.1209,  0.1727, -0.0990, -0.1048,  0.1475,\n",
       "                       0.1774, -0.1214,  0.0921,  0.1571,  0.2078, -0.1314, -0.1645,  0.0881,\n",
       "                      -0.1745,  0.1397,  0.0945,  0.0987,  0.1374, -0.0854, -0.1434, -0.1115,\n",
       "                       0.1067,  0.1780,  0.1224,  0.1561,  0.1499, -0.1513, -0.1097, -0.1238,\n",
       "                      -0.1340,  0.0804,  0.1926, -0.1479, -0.1045, -0.1032, -0.1374,  0.1183,\n",
       "                       0.1358, -0.1251,  0.1598, -0.1382, -0.1570, -0.1134,  0.1026,  0.1187,\n",
       "                      -0.1062,  0.1155,  0.1100,  0.1082, -0.1422,  0.1444, -0.1048,  0.1364,\n",
       "                      -0.1284,  0.1677,  0.0957,  0.1788, -0.1493, -0.1347,  0.1583,  0.0793,\n",
       "                      -0.0963,  0.1278, -0.1209, -0.1473,  0.1657, -0.1697,  0.1246,  0.1506,\n",
       "                      -0.1164,  0.1501, -0.1464, -0.1477, -0.1466, -0.1309, -0.1174, -0.1132,\n",
       "                      -0.1581,  0.2051, -0.1094, -0.1015, -0.1009,  0.1335,  0.1437, -0.1637,\n",
       "                      -0.1358, -0.0613,  0.1022, -0.1402,  0.1354,  0.0952,  0.0912, -0.1199,\n",
       "                       0.1399,  0.2204, -0.1343, -0.1766, -0.1635,  0.1292,  0.1452, -0.1310,\n",
       "                      -0.1232, -0.1337,  0.1654,  0.1383,  0.0899, -0.1154, -0.1536, -0.1102,\n",
       "                      -0.1494,  0.0992,  0.1443,  0.1735, -0.1339,  0.1612,  0.1326,  0.1332,\n",
       "                       0.1286,  0.1615,  0.1699,  0.1261,  0.1280,  0.1376, -0.0957,  0.0937,\n",
       "                      -0.1326,  0.1498,  0.1141, -0.1773,  0.1534,  0.1550,  0.1244,  0.1434,\n",
       "                      -0.1303,  0.1476,  0.1768,  0.0764, -0.1234, -0.1285,  0.1263,  0.1742,\n",
       "                       0.1631, -0.1336,  0.1050, -0.1289, -0.0979, -0.1043,  0.0949, -0.1559,\n",
       "                       0.1216, -0.1357, -0.1508,  0.1403,  0.1439,  0.1608, -0.1520, -0.1326,\n",
       "                       0.1298, -0.1626, -0.1119,  0.1523,  0.1784,  0.1551, -0.1500, -0.1755,\n",
       "                       0.1475, -0.1324, -0.1005,  0.1400,  0.1144,  0.1444, -0.1084, -0.1614,\n",
       "                       0.1008, -0.1127, -0.0972,  0.1259, -0.1294,  0.1116,  0.1433,  0.1106,\n",
       "                      -0.1455, -0.1610, -0.1169, -0.1800,  0.1036, -0.1637,  0.0796,  0.1587,\n",
       "                      -0.1944,  0.1746,  0.1574, -0.1524, -0.1291,  0.1571,  0.1782, -0.1214,\n",
       "                      -0.1413,  0.1348,  0.1815,  0.1168,  0.1111, -0.1794,  0.0932,  0.1650,\n",
       "                      -0.1339,  0.1209, -0.1399, -0.1152,  0.1119, -0.1371,  0.1218,  0.1485,\n",
       "                       0.1177,  0.1281,  0.1423, -0.1155,  0.1082, -0.1439,  0.1909, -0.1099,\n",
       "                       0.1589, -0.1767, -0.1176,  0.1182, -0.2001,  0.1399, -0.1422, -0.1480,\n",
       "                       0.1929,  0.1434,  0.0991,  0.1293, -0.1141, -0.1277, -0.1397,  0.1341,\n",
       "                      -0.1155,  0.1484, -0.1300, -0.0997, -0.1819,  0.1233,  0.0882,  0.1512,\n",
       "                       0.1312, -0.0845, -0.1631, -0.1411, -0.0907, -0.0673,  0.1592,  0.1470,\n",
       "                       0.0885,  0.1566, -0.1523, -0.0830,  0.1319,  0.1184,  0.1442,  0.1701,\n",
       "                      -0.1458, -0.1316, -0.2439,  0.1360,  0.0827, -0.1225, -0.1389,  0.1655,\n",
       "                      -0.1522,  0.1775,  0.1494, -0.0981,  0.1249,  0.1430, -0.1063, -0.1708,\n",
       "                       0.1136,  0.0962, -0.1321, -0.1553,  0.1060,  0.1902, -0.1156, -0.1662,\n",
       "                       0.1229,  0.1741,  0.0986,  0.1048, -0.1578, -0.1012, -0.1616, -0.1076,\n",
       "                       0.1679,  0.1544, -0.1407, -0.1372,  0.1362,  0.1667, -0.0960,  0.0959,\n",
       "                      -0.1563, -0.1419,  0.1583,  0.1516], device='cuda:0')),\n",
       "             ('out.weight',\n",
       "              tensor([[ 0.0391, -0.0864,  0.0044,  ...,  0.0505, -0.0246, -0.0461],\n",
       "                      [ 0.0183, -0.0433,  0.0353,  ...,  0.0627, -0.0632, -0.0368],\n",
       "                      [ 0.0305, -0.0597,  0.0568,  ...,  0.0402, -0.0192, -0.0385],\n",
       "                      ...,\n",
       "                      [ 0.0775, -0.0253,  0.0593,  ...,  0.1100, -0.1711, -0.1090],\n",
       "                      [ 0.0024, -0.0413,  0.0424,  ...,  0.0236, -0.0700, -0.0149],\n",
       "                      [ 0.0868, -0.0872,  0.0499,  ...,  0.0915, -0.0638, -0.0963]],\n",
       "                     device='cuda:0')),\n",
       "             ('out.bias',\n",
       "              tensor([ 0.0121, -0.0325,  0.0002,  ...,  0.0062, -0.0234, -0.0202],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.load(os.path.join(artifact_dir, 'model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
