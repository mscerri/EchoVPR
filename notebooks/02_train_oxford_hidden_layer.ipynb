{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\\src\n",
    "!python setup.py develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import TensorDataset, Subset\n",
    "\n",
    "from configs.utils import get_config_wandb, get_int_from_config\n",
    "from echovpr.trainer.metrics.recall import compute_recall\n",
    "from echovpr.datasets.utils import load_np_file, get_1_hot_encode\n",
    "from echovpr.trainer.eval import eval\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"notebooks/train_oxford_hidden_layer.ipynb\"\n",
    "wandb.login()\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run, config = get_config_wandb(\"configs\\\\train_mlp_oxford.ini\", log, project=\"echovpr_oxford_hl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Datasets\n",
    "day_dataset_info = load_np_file(config['dataset_oxford_day_dataset_file_path'])\n",
    "\n",
    "day_gt = day_dataset_info['ground_truth_indices']\n",
    "\n",
    "day_image_idx = torch.from_numpy(day_dataset_info['image_indices'])\n",
    "image_1_hot = torch.from_numpy(get_1_hot_encode(day_dataset_info['image_indices'], len(day_dataset_info['image_indices']))).type(torch.float)\n",
    "netvlad_repr = torch.from_numpy(load_np_file(config['dataset_oxford_day_netvlad_repr_file_path']))\n",
    "\n",
    "train_dataset = TensorDataset(netvlad_repr, image_1_hot, day_image_idx)\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "train_dataLoader = DataLoader(train_dataset, num_workers=int(config['dataloader_threads']), batch_size=int(config['train_batchsize']), shuffle=True)\n",
    "\n",
    "val_test_splits = load_np_file(config['dataset_oxford_night_val_test_splits_indices_file_path'])\n",
    "night_dataset_info = load_np_file(config['dataset_oxford_night_dataset_file_path'])\n",
    "\n",
    "night_gt = night_dataset_info['ground_truth_indices']\n",
    "netvlad_repr = torch.from_numpy(load_np_file(config['dataset_oxford_night_netvlad_repr_file_path']))\n",
    "night_image_idx = torch.from_numpy(night_dataset_info['image_indices'])\n",
    "\n",
    "night_dataset = TensorDataset(netvlad_repr, night_image_idx)\n",
    "\n",
    "val_dataset = Subset(night_dataset, val_test_splits['val_indices'])\n",
    "print(f\"Val dataset size: {len(val_dataset)}\")\n",
    "val_dataLoader = DataLoader(val_dataset, num_workers=int(config['dataloader_threads']), batch_size=int(config['train_batchsize']), shuffle=True)\n",
    "\n",
    "test_dataset = Subset(night_dataset, val_test_splits['test_indices'])\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "test_dataLoader = DataLoader(test_dataset, num_workers=int(config['dataloader_threads']), batch_size=int(config['train_batchsize']), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init MLP and Lightning Modules\n",
    "in_features=int(config['model_in_features'])\n",
    "hidden_features=int(config['model_hidden_features'])\n",
    "out_features=int(config['model_out_features'])\n",
    "\n",
    "layers = []\n",
    "\n",
    "if hidden_features > 0:\n",
    "  layers.append(('hl', nn.Linear(in_features=in_features, out_features=hidden_features, bias=True)))\n",
    "  out_layer_in_features = hidden_features\n",
    "else:\n",
    "  out_layer_in_features = in_features\n",
    "\n",
    "layers.append(('out', nn.Linear(in_features=out_layer_in_features, out_features=out_features, bias=True)))\n",
    "\n",
    "model = nn.Sequential(OrderedDict(layers))\n",
    "model.to(device)\n",
    "\n",
    "lr = float(config['train_lr'])    \n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.BCEWithLogitsLoss(reduction='mean').to(device)\n",
    "\n",
    "# Watch Model\n",
    "wandb.watch(model, criterion=criterion, log=\"all\", idx=1, log_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_values = [1, 5, 10, 20, 50, 100]\n",
    "top_k = max(n_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = get_int_from_config(config, 'train_max_epochs', 1)\n",
    "num_batches = len(train_dataLoader)\n",
    "\n",
    "steps = 0\n",
    "best_val_recall_at_1 = 0\n",
    "save_best_checkpoint = True\n",
    "\n",
    "model_path = os.path.join(wandb.run.dir, 'model.pt')\n",
    "\n",
    "for epoch in range(1, max_epochs + 1):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for x, y_target, y_idx in train_dataLoader:\n",
    "        steps += 1\n",
    "\n",
    "        x = x.to(device)\n",
    "        y_target = y_target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y = model(x)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, predIdx = torch.topk(y, top_k)\n",
    "            predictions += zip(y_idx.numpy(), predIdx.cpu().numpy())\n",
    "\n",
    "        loss = criterion(y, y_target)\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        \n",
    "        epoch_loss += batch_loss\n",
    "\n",
    "    avg_loss = epoch_loss / num_batches\n",
    "    train_recalls = compute_recall(day_gt, predictions, len(predictions), n_values)\n",
    "    \n",
    "    print(f\"Epoch: {epoch}, Loss: {loss.item()}, Train Metrics: {train_recalls}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_recalls = eval(model, val_dataLoader, night_gt, n_values, top_k)\n",
    "        print(f\"Epoch: {epoch}, Val Metric: {val_recalls}\")\n",
    "\n",
    "        current_val_recall_at_1 = val_recalls[1]\n",
    "\n",
    "        is_better = current_val_recall_at_1 > best_val_recall_at_1\n",
    "\n",
    "        if is_better:\n",
    "            best_val_recall_at_1 = current_val_recall_at_1\n",
    "            test_recalls = eval(model, test_dataLoader, night_gt, n_values, top_k)\n",
    "            print(f\"Epoch: {epoch}, Test Metric: {test_recalls}\")\n",
    "            \n",
    "            if save_best_checkpoint:\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "        else:\n",
    "            test_recalls = {}\n",
    "\n",
    "    log_dic = {'train_loss': avg_loss, \"epoch\": epoch}\n",
    "\n",
    "    for k, v in train_recalls.items():\n",
    "        log_dic[f\"train_recall@{k}\"] = v\n",
    "\n",
    "    for k, v in val_recalls.items():\n",
    "        log_dic[f\"val_recall@{k}\"] = v\n",
    "\n",
    "    for k, v in test_recalls.items():\n",
    "        log_dic[f\"test_recall@{k}\"] = v\n",
    "\n",
    "    wandb.log(log_dic, step=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact = wandb.Artifact(f'hl_model_{run.id}', \"model\", metadata=config)\n",
    "model_artifact.add_file(model_path)\n",
    "wandb.log_artifact(model_artifact, aliases=[\"best\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
