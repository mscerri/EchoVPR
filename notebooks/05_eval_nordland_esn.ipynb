{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\\src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isfile, join\n",
    "\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "from configs.utils import get_config, get_bool_from_config\n",
    "from echovpr.datasets.utils import get_dataset, get_subset_dataset\n",
    "from echovpr.models.utils import get_sparsity\n",
    "from echovpr.models.single_esn import SingleESN\n",
    "from echovpr.models.sparce_layer import SpaRCe\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config(\"configs\\\\train_esn_nordland_full_sweep.ini\", log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_name = 'uos_ml/echovpr/esn_4wkrv7z1:v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init()\n",
    "artifact = run.use_artifact(artifact_name, type='model')\n",
    "artifact_dir = artifact.download()\n",
    "\n",
    "model_file = join(artifact_dir, 'model.pt')\n",
    "esn_model_file = join(artifact_dir, 'esn_model.pt')\n",
    "\n",
    "all_in_one = not isfile(esn_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features=int(config['model_in_features'])\n",
    "reservoir_size=int(config['model_reservoir_size'])\n",
    "out_features=int(config['model_out_features'])\n",
    "\n",
    "esn_alpha = float(config['model_esn_alpha'])\n",
    "esn_gamma = float(config['model_esn_gamma'])\n",
    "esn_rho = float(config['model_esn_rho'])\n",
    "esn_num_connections = int(config['model_esn_num_connections'])\n",
    "sparce_enabled = get_bool_from_config(config, 'model_sparce_enabled')\n",
    "\n",
    "model = nn.ModuleDict()\n",
    "\n",
    "esn_model = SingleESN(\n",
    "  in_features, \n",
    "  reservoir_size, \n",
    "  alpha=esn_alpha, \n",
    "  gamma=esn_gamma, \n",
    "  rho=esn_rho,\n",
    "  sparsity=get_sparsity(esn_num_connections, reservoir_size),\n",
    "  device=device\n",
    ")\n",
    "\n",
    "if all_in_one:\n",
    "  model[\"esn\"] = esn_model\n",
    "\n",
    "if sparce_enabled:\n",
    "  model[\"sparce\"] = SpaRCe(reservoir_size)\n",
    "\n",
    "model[\"out\"] = nn.Linear(in_features=reservoir_size, out_features=out_features, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not all_in_one:\n",
    "  esn_model.load_state_dict(torch.load(esn_model_file))\n",
    "\n",
    "model.load_state_dict(torch.load(model_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not all_in_one:\n",
    "  esn_model.eval().to(device)\n",
    "  \n",
    "model.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summer_dataset = get_dataset(config['dataset_nordland_summer_hidden_repr_file_path'])\n",
    "winter_dataset = get_dataset(config['dataset_nordland_winter_hidden_repr_file_path'])\n",
    "\n",
    "max_n = summer_dataset.tensors[0].max()\n",
    "_ = summer_dataset.tensors[0].divide_(max_n)\n",
    "_ = winter_dataset.tensors[0].divide_(max_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(model, dataLoader, device: torch.device):\n",
    "    x_processed_list = []\n",
    "    y_target_list = []\n",
    "    \n",
    "    for x, y_target in dataLoader:\n",
    "        x = x.to(device)\n",
    "        x_processed = model(x)\n",
    "\n",
    "        x_processed_list.append(x_processed.cpu())\n",
    "        y_target_list.append(y_target)\n",
    "\n",
    "    return (torch.vstack(x_processed_list), torch.vstack(y_target_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Winter dataset size: {len(winter_dataset)}\")\n",
    "winter_dataLoader = DataLoader(winter_dataset, num_workers=int(config['dataloader_threads']), batch_size=int(config['train_batchsize']), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winter_dataset = TensorDataset(*process(esn_model, winter_dataLoader, device))\n",
    "dataset_size = len(winter_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Datasets\n",
    "\n",
    "val_dataset = get_subset_dataset(winter_dataset, config['dataset_nordland_winter_val_limit_indices_file_path'])\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "val_dataLoader = DataLoader(val_dataset, num_workers=int(config['dataloader_threads']), batch_size=int(config['train_batchsize']), shuffle=False)\n",
    "\n",
    "test_dataset = get_subset_dataset(winter_dataset, config['dataset_nordland_winter_test_limit_indices_file_path'])\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "test_dataLoader = DataLoader(test_dataset, num_workers=int(config['dataloader_threads']), batch_size=int(config['train_batchsize']), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset_quantiles = None\n",
    "\n",
    "if sparce_enabled:\n",
    "    # Calculate Training Dataset Quantiles\n",
    "    quantile = float(config['model_sparce_quantile'])\n",
    "    val_dataset_quantiles = torch.quantile(torch.abs(torch.vstack([t[0] for t in val_dataset])), quantile, dim=0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, dataLoader, sparce_enabled, quantiles):\n",
    "    predictions = []\n",
    "    ground_truths = []\n",
    "\n",
    "    with torch.no_grad():    \n",
    "        for x, y_target in dataLoader:\n",
    "\n",
    "            x = x.to(device)\n",
    "            \n",
    "            if sparce_enabled:\n",
    "                x = model[\"sparce\"](x, quantiles)\n",
    "\n",
    "            preds = model[\"out\"](x)\n",
    "\n",
    "            predictions.append(preds.cpu())\n",
    "            ground_truths.append(y_target)\n",
    "\n",
    "    return (torch.vstack(predictions), torch.vstack(ground_truths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = TensorDataset(*get_predictions(model, val_dataLoader, sparce_enabled, val_dataset_quantiles))\n",
    "test_preds = TensorDataset(*get_predictions(model, test_dataLoader, sparce_enabled, val_dataset_quantiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_top_k(predictions, top_k = 100):\n",
    "    top_k_predictions = []\n",
    "    ground_truths = []\n",
    "\n",
    "    for  _, (preds, y_target) in enumerate(predictions):\n",
    "\n",
    "        _, predIdx = torch.topk(preds, top_k)\n",
    "\n",
    "        top_k_predictions.append(predIdx.cpu())\n",
    "        ground_truths.append(torch.argmax(y_target, keepdim=True))\n",
    "\n",
    "    return (torch.vstack(top_k_predictions), torch.vstack(ground_truths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_top_k_preds = TensorDataset(*eval_top_k(val_preds))\n",
    "test_top_k_preds = TensorDataset(*eval_top_k(test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory cleanup\n",
    "del model\n",
    "del val_dataset\n",
    "del val_dataLoader\n",
    "del test_dataset\n",
    "del test_dataLoader\n",
    "del winter_dataset\n",
    "del winter_dataLoader\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recall(gt, predictions, numQ, n_values, recall_str=''):\n",
    "    correct_at_n = np.zeros(len(n_values))\n",
    "    for qIx, pred in enumerate(predictions):\n",
    "        for i, n in enumerate(n_values):\n",
    "            # if in top N then also in top NN, where NN > N\n",
    "            if np.any(np.in1d(pred[:n], gt[qIx])):\n",
    "                correct_at_n[i:] += 1\n",
    "                break\n",
    "    recall_at_n = correct_at_n / numQ\n",
    "    all_recalls = {}  # make dict for output\n",
    "    for i, n in enumerate(n_values):\n",
    "        all_recalls[n] = recall_at_n[i]\n",
    "        print(\"====> Recall {}@{}: {:.4f}\".format(recall_str, n, recall_at_n[i]))\n",
    "    return all_recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = 27592\n",
    "dataset_tolerance = 10\n",
    "\n",
    "def get_positives(gt, dataset_tolerance, dataset_size):\n",
    "    return [list(filter(lambda x: (x >= 0 and x < dataset_size), range(i.item() - dataset_tolerance, i.item() + dataset_tolerance + 1))) for i in gt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_values = [1, 5, 10, 20, 50, 100]\n",
    "gt_val = get_positives(val_top_k_preds.tensors[1], dataset_tolerance, dataset_size)\n",
    "val_recalls = compute_recall(gt_val, val_top_k_preds.tensors[0], len(val_top_k_preds), n_values, 'for Val EchoVPR')\n",
    "gt_test = get_positives(test_top_k_preds.tensors[1], dataset_tolerance, dataset_size)\n",
    "test_recalls = compute_recall(gt_test, test_top_k_preds.tensors[0], len(test_top_k_preds), n_values, 'for Test EchoVPR')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
