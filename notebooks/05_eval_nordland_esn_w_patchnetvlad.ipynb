{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\\src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isfile, join\n",
    "\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from torchmetrics import MetricCollection\n",
    "\n",
    "from configs.utils import get_config, get_config_full, get_int_from_config, get_float_from_config, get_bool_from_config\n",
    "from echovpr.datasets.utils import get_dataset, get_subset_dataset, save_tensor\n",
    "from echovpr.datasets.image_ds import ImageDataset\n",
    "from echovpr.models.utils import get_sparsity\n",
    "from echovpr.models.single_esn import SingleESN\n",
    "from echovpr.models.hier_esn import HierESN\n",
    "from echovpr.models.sparce_layer import SpaRCe\n",
    "from echovpr.trainer.metrics.recall_top_k_metric import RecallTopKMetric\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config(\"configs\\\\train_esn_nordland_full_sweep.ini\", log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init()\n",
    "artifact = run.use_artifact('uos_ml/echovpr/esn_9km0ic3z:v0', type='model')\n",
    "artifact_dir = artifact.download()\n",
    "\n",
    "model_file = join(artifact_dir, 'model.pt')\n",
    "esn_model_file = join(artifact_dir, 'esn_model.pt')\n",
    "\n",
    "all_in_one = not isfile(esn_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features=int(config['model_in_features'])\n",
    "reservoir_size=int(config['model_reservoir_size'])\n",
    "out_features=int(config['model_out_features'])\n",
    "\n",
    "esn_alpha = float(config['model_esn_alpha'])\n",
    "esn_gamma = float(config['model_esn_gamma'])\n",
    "esn_rho = float(config['model_esn_rho'])\n",
    "esn_num_connections = int(config['model_esn_num_connections'])\n",
    "sparce_enabled = get_bool_from_config(config, 'model_sparce_enabled')\n",
    "\n",
    "model = nn.ModuleDict()\n",
    "\n",
    "esn_model = SingleESN(\n",
    "  in_features, \n",
    "  reservoir_size, \n",
    "  alpha=esn_alpha, \n",
    "  gamma=esn_gamma, \n",
    "  rho=esn_rho,\n",
    "  sparsity=get_sparsity(esn_num_connections, reservoir_size),\n",
    "  device=device\n",
    ")\n",
    "\n",
    "if all_in_one:\n",
    "  model[\"esn\"] = esn_model\n",
    "\n",
    "if sparce_enabled:\n",
    "  model[\"sparce\"] = SpaRCe(reservoir_size)\n",
    "\n",
    "model[\"out\"] = nn.Linear(in_features=reservoir_size, out_features=out_features, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not all_in_one:\n",
    "  esn_model.load_state_dict(torch.load(esn_model_file))\n",
    "\n",
    "model.load_state_dict(torch.load(model_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not all_in_one:\n",
    "  esn_model.eval().to(device)\n",
    "  \n",
    "model.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summer_dataset = get_dataset(config['dataset_nordland_summer_hidden_repr_file_path'])\n",
    "winter_dataset = get_dataset(config['dataset_nordland_winter_hidden_repr_file_path'])\n",
    "\n",
    "max_n = summer_dataset.tensors[0].max()\n",
    "_ = summer_dataset.tensors[0].divide_(max_n)\n",
    "_ = winter_dataset.tensors[0].divide_(max_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(model, dataLoader, device: torch.device):\n",
    "    x_processed_list = []\n",
    "    y_target_list = []\n",
    "    \n",
    "    for x, y_target in dataLoader:\n",
    "        x = x.to(device)\n",
    "        x_processed = model(x)\n",
    "\n",
    "        x_processed_list.append(x_processed.cpu())\n",
    "        y_target_list.append(y_target)\n",
    "\n",
    "    return (torch.vstack(x_processed_list), torch.vstack(y_target_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Winter dataset size: {len(winter_dataset)}\")\n",
    "winter_dataLoader = DataLoader(winter_dataset, num_workers=int(config['dataloader_threads']), batch_size=int(config['train_batchsize']), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winter_dataset = TensorDataset(*process(esn_model, winter_dataLoader, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Datasets\n",
    "\n",
    "val_dataset = get_subset_dataset(winter_dataset, config['dataset_nordland_winter_val_limit_indices_file_path'])\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "val_dataLoader = DataLoader(val_dataset, num_workers=int(config['dataloader_threads']), batch_size=int(config['train_batchsize']), shuffle=False)\n",
    "\n",
    "test_dataset = get_subset_dataset(winter_dataset, config['dataset_nordland_winter_test_limit_indices_file_path'])\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "test_dataLoader = DataLoader(test_dataset, num_workers=int(config['dataloader_threads']), batch_size=int(config['train_batchsize']), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset_quantiles = None\n",
    "\n",
    "if sparce_enabled:\n",
    "    # Calculate Training Dataset Quantiles\n",
    "    quantile = float(config['model_sparce_quantile'])\n",
    "    val_dataset_quantiles = torch.quantile(torch.abs(torch.vstack([t[0] for t in val_dataset])), quantile, dim=0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_esn(model, dataLoader, sparce_enabled, quantiles, top_k = 100):\n",
    "    predictions = []\n",
    "    ground_truths = []\n",
    "\n",
    "    with torch.no_grad():    \n",
    "        for x, y_target in dataLoader:\n",
    "\n",
    "            x = x.to(device)\n",
    "            \n",
    "            if sparce_enabled:\n",
    "                x = model[\"sparce\"](x, quantiles)\n",
    "\n",
    "            preds = model[\"out\"](x)\n",
    "\n",
    "            _, predIdx = torch.topk(preds, top_k, dim=1)\n",
    "\n",
    "            predictions.append(predIdx.cpu())\n",
    "            ground_truths.append(torch.argmax(y_target, dim=1, keepdim=True))\n",
    "\n",
    "    return (torch.vstack(predictions), torch.vstack(ground_truths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions = TensorDataset(*eval_esn(model, val_dataLoader, sparce_enabled, val_dataset_quantiles))\n",
    "test_predictions = TensorDataset(*eval_esn(model, test_dataLoader, sparce_enabled, val_dataset_quantiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory cleanup\n",
    "del model\n",
    "del val_dataset\n",
    "del val_dataLoader\n",
    "del test_dataset\n",
    "del test_dataLoader\n",
    "del winter_dataset\n",
    "del winter_dataLoader\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patchnetvlad_config = get_config_full(\"echovpr\\\\configs\\\\eval_patchnetvlad.ini\")\n",
    "patchnetvlad_main_config = patchnetvlad_config['main']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dataset = ImageDataset(patchnetvlad_main_config['dataset_nordland_summer_file_path'], patchnetvlad_main_config['dataset_root_dir'], patchnetvlad_main_config)\n",
    "query_dataset = ImageDataset(patchnetvlad_main_config['dataset_nordland_winter_file_path'], patchnetvlad_main_config['dataset_root_dir'], patchnetvlad_main_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from echovpr.models.netvlad_encoder import NetVLADEncorder\n",
    "from patchnetvlad.tools.local_matcher import calc_keypoint_centers_from_patches, normalise_func\n",
    "from patchnetvlad.tools.patch_matcher import PatchMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = NetVLADEncorder(patchnetvlad_main_config).eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def local_matcher_online(predictions, config, device):\n",
    "#     patch_sizes = [int(s) for s in config['main']['model_patch_sizes'].split(\",\")]\n",
    "#     strides = [int(s) for s in config['main']['model_strides'].split(\",\")]\n",
    "#     patch_weights = np.array(config['feature_match']['patchWeights2Use'].split(\",\")).astype(float)\n",
    "\n",
    "#     all_keypoints = []\n",
    "#     all_indices = []\n",
    "\n",
    "#     for patch_size, stride in zip(patch_sizes, strides):\n",
    "#         # we currently only provide support for square patches, but this can be easily modified for future works\n",
    "#         keypoints, indices = calc_keypoint_centers_from_patches(config['feature_match'], patch_size, patch_size, stride, stride)\n",
    "#         all_keypoints.append(keypoints)\n",
    "#         all_indices.append(indices)\n",
    "\n",
    "#     reordered_preds = []\n",
    "\n",
    "#     matcher = PatchMatcher(config['feature_match']['matcher'], patch_sizes, strides, all_keypoints, all_indices)\n",
    "\n",
    "#     total_preds = len(predictions)\n",
    "\n",
    "#     for i, (pred, q_idx) in enumerate(predictions):\n",
    "#         if i % 10:\n",
    "#             print(f\"Processing query {i+1}/{total_preds}\")\n",
    "            \n",
    "#         diffs = np.zeros((pred.shape[0], len(patch_sizes)))\n",
    "        \n",
    "#         qImg, _ = query_dataset[q_idx]\n",
    "#         _, qfeat = encoder(qImg.unsqueeze(0).to(device))\n",
    "#         qfeat = [torch.transpose(f[1].squeeze(0), 0, 1) for f in qfeat]\n",
    "\n",
    "#         for k, candidate in enumerate(pred):\n",
    "#             dbImg, _ = index_dataset[candidate]\n",
    "#             _, dbfeat = encoder(dbImg.unsqueeze(0).to(device))\n",
    "#             dbfeat = [f[1].squeeze(0) for f in dbfeat]\n",
    "            \n",
    "#             diffs[k, :], _, _ = matcher.match(qfeat, dbfeat)\n",
    "\n",
    "#         diffs = normalise_func(diffs, len(patch_sizes), patch_weights)\n",
    "#         cand_sorted = np.argsort(diffs)\n",
    "#         reordered_preds.append(pred[cand_sorted])\n",
    "    \n",
    "#     return reordered_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from joblib import Parallel, delayed, parallel_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_input_features_dir = \"C:\\\\Users\\\\mscer\\\\dev\\\\Patch-NetVLAD\\\\patchnetvlad\\\\output_features\\\\nordland_index\"\n",
    "query_input_features_dir = \"C:\\\\Users\\\\mscer\\\\dev\\\\Patch-NetVLAD\\\\patchnetvlad\\\\output_features\\\\nordland_query\"\n",
    "input_query_local_features_prefix = join(query_input_features_dir, 'patchfeats')\n",
    "input_query_global_features_prefix = join(query_input_features_dir, 'globalfeats.npy')\n",
    "input_index_local_features_prefix = join(index_input_features_dir, 'patchfeats')\n",
    "input_index_global_features_prefix = join(index_input_features_dir, 'globalfeats.npy')\n",
    "\n",
    "def local_matcher_loop(item, total_preds,patch_sizes, matcher, patch_weights, input_query_local_features_prefix, input_index_local_features_prefix, device):\n",
    "    i, (pred, q_idx) = item\n",
    "\n",
    "    # if i % 1000 == 0:\n",
    "    print(f\"Processing query {i+1}/{total_preds}\")\n",
    "\n",
    "    diffs = np.zeros((pred.shape[0], len(patch_sizes)))\n",
    "        \n",
    "    image_name_query = os.path.splitext(os.path.basename(query_dataset.images[q_idx]))[0]\n",
    "    qfeat = []\n",
    "    for patch_size in patch_sizes:\n",
    "        qfilename = input_query_local_features_prefix + '_' + 'psize{}_'.format(patch_size) + image_name_query + '.npy'\n",
    "        qfeat.append(torch.transpose(torch.tensor(np.load(qfilename), device=device), 0, 1))\n",
    "        # we pre-transpose here to save compute speed\n",
    "        \n",
    "    for k, candidate in enumerate(pred):\n",
    "        image_name_index = os.path.splitext(os.path.basename(index_dataset.images[candidate]))[0]\n",
    "        dbfeat = []\n",
    "        for patch_size in patch_sizes:\n",
    "            dbfilename = input_index_local_features_prefix + '_' + 'psize{}_'.format(patch_size) + image_name_index + '.npy'\n",
    "            dbfeat.append(torch.tensor(np.load(dbfilename), device=device))\n",
    "\n",
    "        diffs[k, :], _, _ = matcher.match(qfeat, dbfeat)\n",
    "\n",
    "    diffs = normalise_func(diffs, len(patch_sizes), patch_weights)\n",
    "    cand_sorted = np.argsort(diffs)\n",
    "\n",
    "    return pred[cand_sorted]\n",
    "\n",
    "def local_matcher(predictions, config, device):\n",
    "    patch_sizes = [int(s) for s in config['main']['model_patch_sizes'].split(\",\")]\n",
    "    strides = [int(s) for s in config['main']['model_strides'].split(\",\")]\n",
    "    patch_weights = np.array(config['feature_match']['patchWeights2Use'].split(\",\")).astype(float)\n",
    "\n",
    "    all_keypoints = []\n",
    "    all_indices = []\n",
    "\n",
    "    for patch_size, stride in zip(patch_sizes, strides):\n",
    "        # we currently only provide support for square patches, but this can be easily modified for future works\n",
    "        keypoints, indices = calc_keypoint_centers_from_patches(config['feature_match'], patch_size, patch_size, stride, stride)\n",
    "        all_keypoints.append(keypoints)\n",
    "        all_indices.append(indices)\n",
    "\n",
    "    reordered_preds = []\n",
    "\n",
    "    matcher = PatchMatcher(config['feature_match']['matcher'], patch_sizes, strides, all_keypoints, all_indices)\n",
    "\n",
    "    total_preds = len(predictions)\n",
    "\n",
    "    reordered_preds = Parallel(n_jobs=20, prefer=\"threads\", require='sharedmem')(delayed(local_matcher_loop)(item, total_preds,patch_sizes, matcher, patch_weights, input_query_local_features_prefix, input_index_local_features_prefix, device) for item in enumerate(predictions))\n",
    "    \n",
    "    # for i, (pred, q_idx) in enumerate(predictions):\n",
    "    #     if i % 1000 == 0:\n",
    "    #         print(f\"Processing query {i+1}/{total_preds}\")\n",
    "            \n",
    "    #     diffs = np.zeros((pred.shape[0], len(patch_sizes)))\n",
    "        \n",
    "    #     image_name_query = os.path.splitext(os.path.basename(query_dataset.images[q_idx]))[0]\n",
    "    #     qfeat = []\n",
    "    #     for patch_size in patch_sizes:\n",
    "    #         qfilename = input_query_local_features_prefix + '_' + 'psize{}_'.format(patch_size) + image_name_query + '.npy'\n",
    "    #         qfeat.append(torch.transpose(torch.tensor(np.load(qfilename), device=device), 0, 1))\n",
    "    #         # we pre-transpose here to save compute speed\n",
    "            \n",
    "    #     for k, candidate in enumerate(pred):\n",
    "    #         image_name_index = os.path.splitext(os.path.basename(index_dataset.images[candidate]))[0]\n",
    "    #         dbfeat = []\n",
    "    #         for patch_size in patch_sizes:\n",
    "    #             dbfilename = input_index_local_features_prefix + '_' + 'psize{}_'.format(patch_size) + image_name_index + '.npy'\n",
    "    #             dbfeat.append(torch.tensor(np.load(dbfilename), device=device))\n",
    "\n",
    "    #         diffs[k, :], _, _ = matcher.match(qfeat, dbfeat)\n",
    "\n",
    "    #     cand_sorted = np.argsort(diffs)\n",
    "    #     diffs = normalise_func(diffs, len(patch_sizes), patch_weights)\n",
    "    #     reordered_preds.append(pred[cand_sorted])\n",
    "    \n",
    "    return reordered_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_predictions_subset = TensorDataset(*val_predictions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reranked_val_predictions = local_matcher_online(val_predictions, patchnetvlad_config, device)\n",
    "reranked_val_predictions = local_matcher(val_predictions, patchnetvlad_config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recall(gt, predictions, numQ, n_values, recall_str=''):\n",
    "    correct_at_n = np.zeros(len(n_values))\n",
    "    for qIx, pred in enumerate(predictions):\n",
    "        for i, n in enumerate(n_values):\n",
    "            # if in top N then also in top NN, where NN > N\n",
    "            if np.any(np.in1d(pred[:n], gt[qIx])):\n",
    "                correct_at_n[i:] += 1\n",
    "                break\n",
    "    recall_at_n = correct_at_n.astype(np.float32) / numQ\n",
    "    all_recalls = {}  # make dict for output\n",
    "    for i, n in enumerate(n_values):\n",
    "        all_recalls[n] = recall_at_n[i]\n",
    "        print(\"====> Recall {}@{}: {:.4f}\".format(recall_str, n, recall_at_n[i]))\n",
    "    return all_recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_values = [1, 5, 10, 20, 50, 100]\n",
    "dataset_size = 27592\n",
    "dataset_tolerance = 10\n",
    "\n",
    "def get_positives(gt, dataset_tolerance, dataset_size):\n",
    "    return [list(filter(lambda x: (x >= 0 and x < dataset_size), range(i.item() - dataset_tolerance, i.item() + dataset_tolerance + 1))) for i in gt]\n",
    "\n",
    "gt_val = get_positives(val_predictions.tensors[1], dataset_tolerance, dataset_size)\n",
    "global_recalls = compute_recall(gt_val, val_predictions.tensors[0], len(val_predictions), n_values, 'for Val EchoVPR')\n",
    "local_recalls = compute_recall(gt_val, reranked_val_predictions, len(val_predictions), n_values, 'for Val EchoVPR+PatchNetVLAD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranked_test_predictions = local_matcher(test_predictions, patchnetvlad_config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = 27592\n",
    "dataset_tolerance = 10\n",
    "\n",
    "def get_positives(gt, dataset_tolerance, dataset_size):\n",
    "    return [list(filter(lambda x: (x >= 0 and x < dataset_size), range(i.item() - dataset_tolerance, i.item() + dataset_tolerance + 1))) for i in gt]\n",
    "\n",
    "gt_test = get_positives(test_predictions.tensors[1], dataset_tolerance, dataset_size)\n",
    "    \n",
    "test_echovpr_recalls = compute_recall(gt_test, test_predictions.tensors[0], len(test_predictions), n_values, 'for Test EchoVPR')\n",
    "test_echovpr_patchnetvlad_recalls = compute_recall(gt_test, reranked_test_predictions, len(test_predictions), n_values, 'for Test EchoVPR+PatchNetVLAD')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
